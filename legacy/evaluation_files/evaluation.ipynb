{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tools_utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtools_utils\u001b[39;00m\u001b[38;5;241m,\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01meval_utils\u001b[39;00m\u001b[38;5;241m,\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mprompt_utils\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmain_functions\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tools_utils'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import tools_utils, eval_utils, prompt_utils\n",
    "import pandas as pd\n",
    "import main_functions\n",
    "\n",
    "from openai import OpenAI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We imported all the necessary modules for the evaluation. Some are internal modules which are already used by the extraction tool. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'eval_utils' from 'c:\\\\Users\\\\paolo\\\\Desktop\\\\T3.4.1_KeywordsTranslation\\\\eval_utils.py'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(main_functions)\n",
    "importlib.reload(tools_utils)\n",
    "importlib.reload(prompt_utils)\n",
    "importlib.reload(eval_utils)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following reads the Excel File with the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = eval_utils.parse_excel_file(\"Dset_Eval_KW_Alignment_Eval_24_03_2025.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Records is a list of dictionaries. Each dictionary specifies the original language of the article, metadata such as title and abstract, and a list of keywords. Each keyword is a dictionary with specified: the label, the wikidata_url, and the match. This is present even if the keyword is not in the original language of the article. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'language': 'pl',\n",
       " 'id': 'oai:revues.org:td/3478',\n",
       " 'title_or': 'Ojczyzna i obczyzna: Irlandia, Polska i Inni',\n",
       " 'title_eng': 'Homeland and garbage: Ireland, Poland and other',\n",
       " 'abstract_or': 'Mówiąc o migracjach do Irlandii z czasów “celtyckiego tygrysa”, można rozróżnić dwa etapy. Na początku w latach 1996–2002 migranci odczuwali prawdziwą dumę z\\xa0rodzimej kultury, w której się wychowali, a jednocześnie wykazywali żywe zainteresowanie irlandzką tradycją. Później jednak, od roku 2002 aż do kryzysu w 2008, nastąpił okres często opisywany jako „bling”, który charakteryzował przepych: nastawienie na materializm oraz\\xa0brak zainteresowania kulturą i kulturową wymianą. Co za tym idzie, wbrew oczekiwaniom zapoczątkowanym przez nowe fuzje, nie rozwinęła się na szerszą skalę irlandzka literatura inspirowana spotkaniami z „innym”. Niewątpliwie jest to zadziwiające, biorąc pod\\xa0uwagę, że tak wiele pozycji z kanonu literatury irlandzkiej zrodziło się z otwartości na „obcego/innego” – poczynając od Swifta i Edgeworth po Joyce’a i McGaherna. Mimo to nadal tli się nadzieja, że przybyszom uda się przekształcić irlandzkie mity i doświadczenia – być może nastąpi to poprzez wzbogacenie ich kulturowych narracji o elementy irlandzkiej rzeczywistości – i że fuzja różnych tradycji dyskursywnych doprowadzi do powstania nowej literatury i kultury.',\n",
       " 'abstract_eng': 'The migrations into the Celtic Tiger (Ireland during its economic boom) seems to have occurred in two phases. The first (ca. 1996 to 2002) saw incomers who were proud of their culture of origin and curious about the Irish tradition. It was followed by a phase of ‘bling’ (2002 to the collapse in 2008) characterized by fast money and little cultural interchange. Society in general seemed more superficial and materialistic, and literature failed to embrace the ‘Other’ as prelude to new fusions. This is surprising, given that many Irish classics – from Swift and Edgeworth to Joyce and McGahern – celebrate the encounter with the ‘Other’. Kiberd argues that Irish myths and experiences might still be reconfigured by incomers, even as their cultural narratives are enriched by their encounter with Ireland. The fusion of the various discursive traditions might lead to new forms in literature and culture, as well as a renewal of consciousness.',\n",
       " 'kws': [{'label': 'migration',\n",
       "   'wikidata_url': ['https://www.wikidata.org/wiki/Q1800545',\n",
       "    'https://www.wikidata.org/wiki/Q177626'],\n",
       "   'match': 'e'},\n",
       "  {'label': 'Irishness',\n",
       "   'wikidata_url': ['https://www.wikidata.org/wiki/Q111915753'],\n",
       "   'match': 'e'},\n",
       "  {'label': 'globalization',\n",
       "   'wikidata_url': ['https://www.wikidata.org/wiki/Q7181'],\n",
       "   'match': 'e'},\n",
       "  {'label': 'inny/obcy',\n",
       "   'wikidata_url': ['https://www.wikidata.org/wiki/Q108982186',\n",
       "    'https://www.wikidata.org/wiki/Q109014493'],\n",
       "   'match': 'r'},\n",
       "  {'label': 'globalizacja',\n",
       "   'wikidata_url': ['https://www.wikidata.org/wiki/Q7181'],\n",
       "   'match': 'e'},\n",
       "  {'label': 'Polska',\n",
       "   'wikidata_url': ['https://www.wikidata.org/wiki/Q36'],\n",
       "   'match': 'e'},\n",
       "  {'label': 'Irlandia',\n",
       "   'wikidata_url': ['https://www.wikidata.org/wiki/Q22890'],\n",
       "   'match': 'e'}]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In what follows, we initialize the LLM client. The evaluation has been ran with the OpenAI model, so code to activate the OpenAI client is shown here. However, the evaluation function can be used with any OpenAI-compatible LLM API. \n",
    "\n",
    "The API key must be specified in order to run the evaluation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_OPENAI_API_KEY = \"YOUR_API_KEY\"\n",
    "\n",
    "\t\n",
    "\n",
    "client = OpenAI(api_key=MY_OPENAI_API_KEY)\n",
    "model_name = \"gpt-4o-mini\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell runs the evaluation. It takes as input the xlsx file and iterates over the articles in the dataset. For each keyword in the article, it executes the function useLLM_back_and_forth (which is defined in main_functions.py)\n",
    "\n",
    "\n",
    "The function useLLM_back_and_forth generates a prompt for potential entities generation (given a keyword, find the corresponding entity in Wikidata). NUM_NAMES (set by default to 10 in the function, in line with the paper) is the maximum number of entities that can be generated by the potential entity generator. After the entities are generated, they are added to the EntitySelectionPrompt. This prompt asks a model to select the most relevant entities. The number of entities selected are the best number_of_entities matching entities. In line with the evaluation showed in the paper, the number of entities selected is set by default to 1. \n",
    "\n",
    "The code includes progress tracking and a mechanism for backup of results. It generates a JSON file where the information for each article is enriched with the LLM annotation for each keyword. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:   1%|▏         | 3/202 [01:03<1:19:55, 24.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving partial results at record 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:   3%|▎         | 6/202 [01:53<1:02:35, 19.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving partial results at record 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:   4%|▍         | 9/202 [02:38<49:32, 15.40s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving partial results at record 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:   6%|▌         | 12/202 [03:12<34:15, 10.82s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving partial results at record 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:   7%|▋         | 15/202 [04:24<53:54, 17.30s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving partial results at record 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:   9%|▉         | 18/202 [06:14<1:26:27, 28.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving partial results at record 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:  10%|█         | 21/202 [07:15<1:10:32, 23.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving partial results at record 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:  12%|█▏        | 24/202 [09:29<2:01:09, 40.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving partial results at record 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:  13%|█▎        | 27/202 [10:52<1:36:19, 33.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving partial results at record 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:  15%|█▍        | 30/202 [12:01<1:14:54, 26.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving partial results at record 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:  16%|█▋        | 33/202 [14:18<1:48:22, 38.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving partial results at record 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:  18%|█▊        | 36/202 [15:50<1:34:05, 34.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving partial results at record 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:  19%|█▉        | 39/202 [17:06<1:20:14, 29.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving partial results at record 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:  21%|██        | 42/202 [18:32<1:16:10, 28.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving partial results at record 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:  22%|██▏       | 45/202 [19:57<1:20:07, 30.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving partial results at record 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:  24%|██▍       | 48/202 [21:41<1:36:55, 37.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving partial results at record 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:  25%|██▌       | 51/202 [22:39<1:02:49, 24.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving partial results at record 51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:  27%|██▋       | 54/202 [23:51<1:01:03, 24.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving partial results at record 54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:  28%|██▊       | 57/202 [25:20<1:07:58, 28.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving partial results at record 57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:  30%|██▉       | 60/202 [27:31<1:18:00, 32.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving partial results at record 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:  31%|███       | 63/202 [28:27<54:45, 23.63s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving partial results at record 63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:  33%|███▎      | 66/202 [29:47<56:56, 25.12s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving partial results at record 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:  34%|███▍      | 69/202 [31:32<1:11:19, 32.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving partial results at record 69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:  36%|███▌      | 72/202 [32:56<1:04:58, 29.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving partial results at record 72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:  37%|███▋      | 75/202 [34:01<49:46, 23.52s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving partial results at record 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:  39%|███▊      | 78/202 [35:53<1:12:56, 35.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving partial results at record 78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:  40%|████      | 81/202 [37:48<1:12:46, 36.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving partial results at record 81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:  42%|████▏     | 84/202 [39:29<1:05:44, 33.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving partial results at record 84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:  43%|████▎     | 87/202 [41:04<1:07:51, 35.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving partial results at record 87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:  45%|████▍     | 90/202 [42:31<1:03:23, 33.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving partial results at record 90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:  46%|████▌     | 93/202 [44:31<1:04:08, 35.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving partial results at record 93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:  48%|████▊     | 96/202 [48:18<1:44:48, 59.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving partial results at record 96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:  49%|████▉     | 99/202 [50:01<1:10:38, 41.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving partial results at record 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:  50%|█████     | 102/202 [51:48<1:03:13, 37.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving partial results at record 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:  52%|█████▏    | 105/202 [53:23<1:00:20, 37.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving partial results at record 105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:  53%|█████▎    | 108/202 [54:39<47:09, 30.11s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving partial results at record 108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:  55%|█████▍    | 111/202 [55:33<33:09, 21.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving partial results at record 111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:  56%|█████▋    | 114/202 [56:34<29:34, 20.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving partial results at record 114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:  58%|█████▊    | 117/202 [58:02<32:49, 23.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving partial results at record 117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:  59%|█████▉    | 120/202 [1:00:09<45:37, 33.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving partial results at record 120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:  61%|██████    | 123/202 [1:01:46<44:38, 33.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving partial results at record 123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:  62%|██████▏   | 126/202 [1:03:14<37:22, 29.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving partial results at record 126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:  64%|██████▍   | 129/202 [1:05:07<37:38, 30.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving partial results at record 129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:  65%|██████▌   | 132/202 [1:06:31<33:21, 28.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving partial results at record 132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:  67%|██████▋   | 135/202 [1:07:57<32:51, 29.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving partial results at record 135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:  68%|██████▊   | 138/202 [1:09:16<28:27, 26.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving partial results at record 138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:  70%|██████▉   | 141/202 [1:10:17<21:11, 20.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving partial results at record 141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:  71%|███████▏  | 144/202 [1:12:11<30:53, 31.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving partial results at record 144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:  73%|███████▎  | 147/202 [1:13:38<28:17, 30.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving partial results at record 147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:  74%|███████▍  | 150/202 [1:15:55<40:23, 46.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving partial results at record 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:  76%|███████▌  | 153/202 [1:17:41<33:44, 41.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving partial results at record 153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:  77%|███████▋  | 156/202 [1:19:47<30:33, 39.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving partial results at record 156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:  79%|███████▊  | 159/202 [1:21:28<24:54, 34.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving partial results at record 159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:  80%|████████  | 162/202 [1:23:57<29:05, 43.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving partial results at record 162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:  82%|████████▏ | 165/202 [1:26:13<30:15, 49.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving partial results at record 165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:  83%|████████▎ | 168/202 [1:28:16<24:57, 44.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving partial results at record 168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:  85%|████████▍ | 171/202 [1:30:40<25:59, 50.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving partial results at record 171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:  86%|████████▌ | 174/202 [1:32:02<15:51, 33.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving partial results at record 174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:  88%|████████▊ | 177/202 [1:33:03<10:36, 25.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving partial results at record 177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:  89%|████████▉ | 180/202 [1:36:15<19:01, 51.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving partial results at record 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:  91%|█████████ | 183/202 [1:38:32<14:52, 46.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving partial results at record 183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:  92%|█████████▏| 186/202 [1:39:48<08:25, 31.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving partial results at record 186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:  94%|█████████▎| 189/202 [1:40:33<04:31, 20.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving partial results at record 189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:  95%|█████████▌| 192/202 [1:42:14<04:40, 28.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving partial results at record 192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:  97%|█████████▋| 195/202 [1:44:12<04:23, 37.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving partial results at record 195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:  98%|█████████▊| 198/202 [1:46:48<03:27, 51.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving partial results at record 198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:  99%|█████████▉| 200/202 [1:47:46<01:19, 39.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving partial results at record 201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records: 100%|██████████| 202/202 [1:47:46<00:00, 32.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All records processed, saving final results.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "SAVE_EVERY = 3  # Number of records after which to save\n",
    "results_file = \"C:/Users/paolo/Desktop/T3.4.1_KeywordsTranslation/data_eval_03242025.json\"\n",
    "\n",
    "for record_idx, record in enumerate(tqdm(records, desc=\"Processing records\")):\n",
    "    for i, kw in enumerate(\n",
    "        tqdm(record['kws'], \n",
    "             total=len(record['kws']), \n",
    "             desc=f\"Processing keywords for record {record_idx + 1}\", \n",
    "             leave=False\n",
    "        )\n",
    "    ):\n",
    "        \n",
    "        try:\n",
    "            llm_uris = main_functions.useLLM_back_and_forth(\n",
    "                record['language'], \n",
    "                record['title_or'], \n",
    "                record['abstract_or'], \n",
    "                kw['label'], \n",
    "                client, \n",
    "                model_name\n",
    "            )\n",
    "            record['kws'][i]['llm_uris'] = llm_uris\n",
    "        except Exception as e:\n",
    "            print(\"LLM URIs cannot be computed:\", e)\n",
    "            record['kws'][i]['llm_uris'] = []\n",
    "\n",
    "\n",
    "    # Periodically save (for example, every 10 records)\n",
    "    if (record_idx + 1) % SAVE_EVERY == 0:\n",
    "        print(f\"Saving partial results at record {record_idx + 1}\")\n",
    "        with open(results_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(records, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# Final save after all records are processed\n",
    "print(\"All records processed, saving final results.\")\n",
    "with open(results_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(records, f, ensure_ascii=False, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell of code contains some required adjustments to the evaluation output for the results analysis. These adjustments mainly involve string parsing. Running this cell is required to obtain the statistics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "results_file = \"C:/Users/paolo/Desktop/T3.4.1_KeywordsTranslation/data_eval_03242025.json\"\n",
    "\n",
    "\n",
    "new_records = []\n",
    "\n",
    "with open(results_file, 'r', encoding='utf-8') as f:\n",
    "    records = json.load(f)\n",
    "\n",
    "\n",
    "for record in records:\n",
    "    new_record = record\n",
    "    for i, kw in enumerate(record['kws']):\n",
    "        if len(kw['llm_uris']) == 3 and kw['llm_uris'][1] == \"wikidata\":\n",
    "            new_record['kws'][i]['llm_uris'] = ['.'.join(kw['llm_uris'])]\n",
    "    new_records.append(new_record)\n",
    "\n",
    "\n",
    "new_results_file = \"C:/Users/paolo/Desktop/T3.4.1_KeywordsTranslation/data_eval_03242025_nuovo.json\"\n",
    "with open(new_results_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(new_records, f, ensure_ascii=False, indent=2)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following two cells can be used to obtain the statistics. As can be seen, the recall, precision, and the F1 scores are printed. They are printed for all the examples, for language (that is, we distinguish the results based on the original language of the article of the keyword), and by match type (where for match type we consider how match the Wikidata URL matches the actual keyword, this could be 'e' - exact match -, or 'r' - related match).\n",
    "\n",
    "As can be seen in the example below, the code prints a report with the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# eval_results generation\n",
    "\n",
    "new_results_file = \"C:/Users/paolo/Desktop/T3.4.1_KeywordsTranslation/data_eval_03242025_nuovo.json\"\n",
    "\n",
    "with open(new_results_file, 'r', encoding='utf-8') as f:\n",
    "    records = json.load(f)\n",
    "\n",
    "languages = set(record['language'] for record in records)\n",
    "\n",
    "scores_llm = {\n",
    "    \"Total\": {\n",
    "        \"recall\": {\"Sum\": 0, \"Size\": 0},\n",
    "        \"precision\": {\"Sum\": 0, \"Size\": 0},\n",
    "        \"f1\": {\"Sum\": 0, \"Size\": 0}\n",
    "    },\n",
    "    \"Per_match_type\": {\n",
    "        \"e\": {\n",
    "            \"recall\": {\"Sum\": 0, \"Size\": 0},\n",
    "            \"precision\": {\"Sum\": 0, \"Size\": 0},\n",
    "            \"f1\": {\"Sum\": 0, \"Size\": 0}\n",
    "        },\n",
    "        \"r\": {\n",
    "            \"recall\": {\"Sum\": 0, \"Size\": 0},\n",
    "            \"precision\": {\"Sum\": 0, \"Size\": 0},\n",
    "            \"f1\": {\"Sum\": 0, \"Size\": 0}\n",
    "        }\n",
    "    },\n",
    "    \"Per_language\": {\n",
    "        language: {\n",
    "            \"recall\": {\"Sum\": 0, \"Size\": 0},\n",
    "            \"precision\": {\"Sum\": 0, \"Size\": 0},\n",
    "            \"f1\": {\"Sum\": 0, \"Size\": 0}\n",
    "        } for language in languages\n",
    "    }\n",
    "}\n",
    "\n",
    "for record in records:\n",
    "    for i, kw in enumerate(record['kws']):\n",
    "        if kw['match'] in (\"e\", \"r\"):\n",
    "            correct_uris = [\n",
    "                url.replace(\"https\", \"http\").replace(\"/wiki/\", \"/entity/\")\n",
    "                for url in kw['wikidata_url']\n",
    "            ]\n",
    "            retrieved_uris_llm = kw['llm_uris']\n",
    "            recall_llm = eval_utils.compute_recall(correct_uris, retrieved_uris_llm)\n",
    "            precision_llm = eval_utils.compute_precision(correct_uris, retrieved_uris_llm)\n",
    "            \n",
    "            # Calcolo del punteggio F1 con controllo per divisione per zero\n",
    "            if (precision_llm + recall_llm) > 0:\n",
    "                f1_llm = 2 * precision_llm * recall_llm / (precision_llm + recall_llm)\n",
    "            else:\n",
    "                f1_llm = 0\n",
    "\n",
    "            # Aggiornamento dei punteggi totali\n",
    "            scores_llm[\"Total\"][\"recall\"][\"Sum\"] += recall_llm\n",
    "            scores_llm[\"Total\"][\"recall\"][\"Size\"] += 1\n",
    "            scores_llm[\"Total\"][\"precision\"][\"Sum\"] += precision_llm\n",
    "            scores_llm[\"Total\"][\"precision\"][\"Size\"] += 1\n",
    "            scores_llm[\"Total\"][\"f1\"][\"Sum\"] += f1_llm\n",
    "            scores_llm[\"Total\"][\"f1\"][\"Size\"] += 1\n",
    "\n",
    "            # Aggiornamento dei punteggi per tipo di match\n",
    "            scores_llm[\"Per_match_type\"][kw['match']][\"recall\"][\"Sum\"] += recall_llm\n",
    "            scores_llm[\"Per_match_type\"][kw['match']][\"recall\"][\"Size\"] += 1\n",
    "            scores_llm[\"Per_match_type\"][kw['match']][\"precision\"][\"Sum\"] += precision_llm\n",
    "            scores_llm[\"Per_match_type\"][kw['match']][\"precision\"][\"Size\"] += 1\n",
    "            scores_llm[\"Per_match_type\"][kw['match']][\"f1\"][\"Sum\"] += f1_llm\n",
    "            scores_llm[\"Per_match_type\"][kw['match']][\"f1\"][\"Size\"] += 1\n",
    "\n",
    "            # Aggiornamento dei punteggi per lingua\n",
    "            scores_llm[\"Per_language\"][record['language']][\"recall\"][\"Sum\"] += recall_llm\n",
    "            scores_llm[\"Per_language\"][record['language']][\"recall\"][\"Size\"] += 1\n",
    "            scores_llm[\"Per_language\"][record['language']][\"precision\"][\"Sum\"] += precision_llm\n",
    "            scores_llm[\"Per_language\"][record['language']][\"precision\"][\"Size\"] += 1\n",
    "            scores_llm[\"Per_language\"][record['language']][\"f1\"][\"Sum\"] += f1_llm\n",
    "            scores_llm[\"Per_language\"][record['language']][\"f1\"][\"Size\"] += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== SYSTEM METRICS REPORT ========\n",
      "\n",
      "--- TOTAL ---\n",
      "LLM Recall:    0.5576\n",
      "LLM Precision: 0.5758\n",
      "LLM F1:        0.5634\n",
      "\n",
      "--- PER MATCH TYPE ---\n",
      "\n",
      "Match Type: e\n",
      "  LLM Recall:    0.6428\n",
      "  LLM Precision: 0.6577\n",
      "  LLM F1:        0.6477\n",
      "\n",
      "Match Type: r\n",
      "  LLM Recall:    0.1999\n",
      "  LLM Precision: 0.2321\n",
      "  LLM F1:        0.2096\n",
      "\n",
      "--- PER LANGUAGE ---\n",
      "\n",
      "Language: ar\n",
      "  LLM Recall:    0.6351\n",
      "  LLM Precision: 0.6486\n",
      "  LLM F1:        0.6396\n",
      "\n",
      "Language: ca\n",
      "  LLM Recall:    0.5714\n",
      "  LLM Precision: 0.5714\n",
      "  LLM F1:        0.5714\n",
      "\n",
      "Language: da\n",
      "  LLM Recall:    0.3750\n",
      "  LLM Precision: 0.3750\n",
      "  LLM F1:        0.3750\n",
      "\n",
      "Language: de\n",
      "  LLM Recall:    0.4886\n",
      "  LLM Precision: 0.5000\n",
      "  LLM F1:        0.4924\n",
      "\n",
      "Language: el\n",
      "  LLM Recall:    0.6410\n",
      "  LLM Precision: 0.6496\n",
      "  LLM F1:        0.6439\n",
      "\n",
      "Language: en\n",
      "  LLM Recall:    0.5969\n",
      "  LLM Precision: 0.6259\n",
      "  LLM F1:        0.6059\n",
      "\n",
      "Language: es\n",
      "  LLM Recall:    0.5068\n",
      "  LLM Precision: 0.5479\n",
      "  LLM F1:        0.5205\n",
      "\n",
      "Language: fi\n",
      "  LLM Recall:    0.4508\n",
      "  LLM Precision: 0.4571\n",
      "  LLM F1:        0.4524\n",
      "\n",
      "Language: fr\n",
      "  LLM Recall:    0.6117\n",
      "  LLM Precision: 0.6250\n",
      "  LLM F1:        0.6155\n",
      "\n",
      "Language: he\n",
      "  LLM Recall:    0.5833\n",
      "  LLM Precision: 0.6667\n",
      "  LLM F1:        0.6111\n",
      "\n",
      "Language: hr\n",
      "  LLM Recall:    0.5137\n",
      "  LLM Precision: 0.5410\n",
      "  LLM F1:        0.5219\n",
      "\n",
      "Language: hu\n",
      "  LLM Recall:    0.6146\n",
      "  LLM Precision: 0.6406\n",
      "  LLM F1:        0.6224\n",
      "\n",
      "Language: it\n",
      "  LLM Recall:    0.6667\n",
      "  LLM Precision: 0.6667\n",
      "  LLM F1:        0.6667\n",
      "\n",
      "Language: nan\n",
      "  LLM Recall:    0.0000\n",
      "  LLM Precision: 0.0000\n",
      "  LLM F1:        0.0000\n",
      "\n",
      "Language: nl\n",
      "  LLM Recall:    0.5677\n",
      "  LLM Precision: 0.6042\n",
      "  LLM F1:        0.5799\n",
      "\n",
      "Language: pl\n",
      "  LLM Recall:    0.5735\n",
      "  LLM Precision: 0.5882\n",
      "  LLM F1:        0.5784\n",
      "\n",
      "Language: pt\n",
      "  LLM Recall:    0.5880\n",
      "  LLM Precision: 0.6080\n",
      "  LLM F1:        0.5947\n",
      "\n",
      "Language: sl\n",
      "  LLM Recall:    0.5093\n",
      "  LLM Precision: 0.5278\n",
      "  LLM F1:        0.5154\n",
      "\n",
      "Language: sq\n",
      "  LLM Recall:    0.5714\n",
      "  LLM Precision: 0.5714\n",
      "  LLM F1:        0.5714\n",
      "\n",
      "Language: sv\n",
      "  LLM Recall:    0.5377\n",
      "  LLM Precision: 0.5472\n",
      "  LLM F1:        0.5409\n",
      "\n",
      "Language: tr\n",
      "  LLM Recall:    0.5623\n",
      "  LLM Precision: 0.5859\n",
      "  LLM F1:        0.5690\n",
      "\n",
      "Language: uk\n",
      "  LLM Recall:    0.4338\n",
      "  LLM Precision: 0.4412\n",
      "  LLM F1:        0.4363\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def compute_mean_metrics(stats_dict):\n",
    "    \"\"\"\n",
    "    Dato un dizionario con la struttura:\n",
    "    {\n",
    "      'Total': {\n",
    "        'recall': {'Sum': x, 'Size': y},\n",
    "        'precision': {'Sum': x2, 'Size': y2},\n",
    "        'f1': {'Sum': x3, 'Size': y3}\n",
    "      },\n",
    "      'Per_match_type': {\n",
    "        'e': {\n",
    "          'recall': {'Sum': x, 'Size': y},\n",
    "          'precision': {'Sum': x2, 'Size': y2},\n",
    "          'f1': {'Sum': x3, 'Size': y3}\n",
    "        },\n",
    "        ...\n",
    "      },\n",
    "      'Per_language': {\n",
    "        'fr': {\n",
    "          'recall': {'Sum': x, 'Size': y},\n",
    "          'precision': {'Sum': x2, 'Size': y2},\n",
    "          'f1': {'Sum': x3, 'Size': y3}\n",
    "        },\n",
    "        ...\n",
    "      }\n",
    "    }\n",
    "\n",
    "    Restituisce un dizionario con i valori medi di recall, precision e f1.\n",
    "    \"\"\"\n",
    "    mean_dict = {\n",
    "        'Total': {},\n",
    "        'Per_match_type': {},\n",
    "        'Per_language': {}\n",
    "    }\n",
    "    \n",
    "    # --- 1) TOTAL ---\n",
    "    if 'Total' in stats_dict:\n",
    "        total_recall_sum = stats_dict['Total']['recall']['Sum']\n",
    "        total_recall_size = stats_dict['Total']['recall']['Size']\n",
    "        total_precision_sum = stats_dict['Total']['precision']['Sum']\n",
    "        total_precision_size = stats_dict['Total']['precision']['Size']\n",
    "        \n",
    "        mean_dict['Total']['recall'] = total_recall_sum / total_recall_size if total_recall_size != 0 else 0\n",
    "        mean_dict['Total']['precision'] = total_precision_sum / total_precision_size if total_precision_size != 0 else 0\n",
    "        \n",
    "        if 'f1' in stats_dict['Total']:\n",
    "            total_f1_sum = stats_dict['Total']['f1']['Sum']\n",
    "            total_f1_size = stats_dict['Total']['f1']['Size']\n",
    "            mean_dict['Total']['f1'] = total_f1_sum / total_f1_size if total_f1_size != 0 else 0\n",
    "\n",
    "    # --- 2) PER MATCH TYPE ---\n",
    "    if 'Per_match_type' in stats_dict:\n",
    "        for match_type, metrics in stats_dict['Per_match_type'].items():\n",
    "            recall_sum = metrics['recall']['Sum']\n",
    "            recall_size = metrics['recall']['Size']\n",
    "            precision_sum = metrics['precision']['Sum']\n",
    "            precision_size = metrics['precision']['Size']\n",
    "            \n",
    "            mean_rec = recall_sum / recall_size if recall_size != 0 else 0\n",
    "            mean_prec = precision_sum / precision_size if precision_size != 0 else 0\n",
    "            \n",
    "            mean_dict['Per_match_type'][match_type] = {\n",
    "                'recall': mean_rec,\n",
    "                'precision': mean_prec\n",
    "            }\n",
    "            if 'f1' in metrics:\n",
    "                f1_sum = metrics['f1']['Sum']\n",
    "                f1_size = metrics['f1']['Size']\n",
    "                mean_dict['Per_match_type'][match_type]['f1'] = f1_sum / f1_size if f1_size != 0 else 0\n",
    "\n",
    "    # --- 3) PER LANGUAGE ---\n",
    "    if 'Per_language' in stats_dict:\n",
    "        for lang, metrics in stats_dict['Per_language'].items():\n",
    "            recall_sum = metrics['recall']['Sum']\n",
    "            recall_size = metrics['recall']['Size']\n",
    "            precision_sum = metrics['precision']['Sum']\n",
    "            precision_size = metrics['precision']['Size']\n",
    "            \n",
    "            mean_rec = recall_sum / recall_size if recall_size != 0 else 0\n",
    "            mean_prec = precision_sum / precision_size if precision_size != 0 else 0\n",
    "            \n",
    "            mean_dict['Per_language'][lang] = {\n",
    "                'recall': mean_rec,\n",
    "                'precision': mean_prec\n",
    "            }\n",
    "            if 'f1' in metrics:\n",
    "                f1_sum = metrics['f1']['Sum']\n",
    "                f1_size = metrics['f1']['Size']\n",
    "                mean_dict['Per_language'][lang]['f1'] = f1_sum / f1_size if f1_size != 0 else 0\n",
    "                \n",
    "    return mean_dict\n",
    "\n",
    "\n",
    "def print_system_report(system_dict):\n",
    "    \"\"\"\n",
    "    Stampa un report leggibile dei risultati del sistema (LLM) per Total,\n",
    "    Per_match_type e Per_language includendo F1.\n",
    "    \"\"\"\n",
    "    system_means = compute_mean_metrics(system_dict)\n",
    "    \n",
    "    print(\"======== SYSTEM METRICS REPORT ========\")\n",
    "    \n",
    "    # --- 1) TOTAL ---\n",
    "    print(\"\\n--- TOTAL ---\")\n",
    "    total = system_means.get('Total', {})\n",
    "    if total:\n",
    "        print(f\"LLM Recall:    {total.get('recall', 0):.4f}\")\n",
    "        print(f\"LLM Precision: {total.get('precision', 0):.4f}\")\n",
    "        print(f\"LLM F1:        {total.get('f1', 0):.4f}\")\n",
    "    else:\n",
    "        print(\"No total data found.\")\n",
    "    \n",
    "    # --- 2) PER MATCH TYPE ---\n",
    "    print(\"\\n--- PER MATCH TYPE ---\")\n",
    "    per_match_data = system_means.get('Per_match_type', {})\n",
    "    for mtype, vals in per_match_data.items():\n",
    "        print(f\"\\nMatch Type: {mtype}\")\n",
    "        print(f\"  LLM Recall:    {vals.get('recall', 0):.4f}\")\n",
    "        print(f\"  LLM Precision: {vals.get('precision', 0):.4f}\")\n",
    "        print(f\"  LLM F1:        {vals.get('f1', 0):.4f}\")\n",
    "    \n",
    "    # --- 3) PER LANGUAGE ---\n",
    "    print(\"\\n--- PER LANGUAGE ---\")\n",
    "    per_lang_data = system_means.get('Per_language', {})\n",
    "    # Ordinamento convertendo le chiavi in stringa per evitare errori se sono di tipo misto\n",
    "    for lang, vals in sorted(per_lang_data.items(), key=lambda x: str(x[0])):\n",
    "        print(f\"\\nLanguage: {lang}\")\n",
    "        print(f\"  LLM Recall:    {vals.get('recall', 0):.4f}\")\n",
    "        print(f\"  LLM Precision: {vals.get('precision', 0):.4f}\")\n",
    "        print(f\"  LLM F1:        {vals.get('f1', 0):.4f}\")\n",
    "\n",
    "\n",
    "# Esempio di utilizzo:\n",
    "# Supponiamo che 'scores_llm' contenga i risultati del sistema (LLM)\n",
    "# Ad esempio, scores_llm è stato popolato precedentemente nel codice.\n",
    "print_system_report(scores_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
